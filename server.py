from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import requests
import logging
import random
import urllib.parse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Genisi ---
API_KEY = "sk_JHTVJDFsV7uiHdMVFqNKwzY8DZkhw0Oz"
BASE_URL = "https://gen.pollinations.ai"

# --- Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ---
MODEL_CHAT_FAST = "openai"
MODEL_CHAT_CODE = "qwen-coder"
MODEL_IMAGE = "nanobanana-pro"
MODEL_VIDEO = "veo"  # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø¬Ø¯ÙŠØ¯

def get_auth_headers():
    return {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }

def resolve_model(text, has_file, user_mode):
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©"""
    text_lower = text.lower()
    
    # 1. Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø§Ù„ØµØ±ÙŠØ­ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
    if user_mode == "veo":
        return "VIDEO", MODEL_VIDEO
    if user_mode == "openai":
        return "TEXT", MODEL_CHAT_FAST
    if user_mode == "qwen-coder":
        return "TEXT", MODEL_CHAT_CODE
    
    # 2. Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Auto)
    
    # Ù‡Ù„ ÙŠØ·Ù„Ø¨ ÙÙŠØ¯ÙŠÙˆØŸ
    video_keywords = ["video", "movie", "clip", "ÙÙŠØ¯ÙŠÙˆ", "Ù…Ù‚Ø·Ø¹", "ÙÙŠÙ„Ù…", "ØªØ­Ø±ÙŠÙƒ"]
    if any(k in text_lower for k in video_keywords):
        return "VIDEO", MODEL_VIDEO

    # Ù‡Ù„ ÙŠØ·Ù„Ø¨ ØµÙˆØ±Ø©ØŸ
    image_keywords = ["Ø§Ø±Ø³Ù…", "ØµÙˆØ±Ø©", "ØªØ®ÙŠÙ„", "draw", "generate image", "paint"]
    if any(k in text_lower for k in image_keywords):
        return "IMAGE", MODEL_IMAGE

    # Ù‡Ù„ ÙŠØ·Ù„Ø¨ ÙƒÙˆØ¯ Ø£Ùˆ ÙŠÙˆØ¬Ø¯ Ù…Ù„ÙØŸ
    code_keywords = ["code", "python", "java", "html", "error", "debug", "api", "ÙƒÙˆØ¯", "Ø¨Ø±Ù…Ø¬Ø©"]
    if has_file or any(k in text_lower for k in code_keywords):
        return "TEXT", MODEL_CHAT_CODE
    
    # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
    return "TEXT", MODEL_CHAT_FAST

def translate_prompt(text):
    """ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙˆØµÙ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØµÙˆØ± ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ)"""
    try:
        payload = {
            "model": MODEL_CHAT_FAST,
            "messages": [
                {"role": "system", "content": "Translate to English description. Output ONLY translation."},
                {"role": "user", "content": text}
            ]
        }
        response = requests.post(
            f"{BASE_URL}/v1/chat/completions", 
            headers=get_auth_headers(), 
            json=payload, timeout=10
        )
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
    except:
        pass
    return text

@app.route('/')
def home():
    return send_from_directory('.', 'index.html')

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        user_input = data.get('message', '')
        file_content = data.get('file_content', '')
        file_name = data.get('file_name', '')
        user_mode = data.get('model_mode', 'auto')

        if not user_input and not file_content:
            return jsonify({"reply": "Empty request"}), 400

        full_context = user_input
        if file_content:
            full_context += f"\n\nFile: {file_name}\n{file_content}"

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙŠØ©
        intent, selected_model = resolve_model(user_input, bool(file_content), user_mode)

        # ---------------------------------------------
        # ğŸ¥ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Veo)
        # ---------------------------------------------
        if intent == "VIDEO":
            english_prompt = translate_prompt(user_input)
            encoded_prompt = urllib.parse.quote(english_prompt)
            seed = random.randint(0, 999999)
            
            # Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (ÙŠØ³ØªØ®Ø¯Ù… Ù†ÙØ³ endpoint Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ† Ù…Ø¹ model=veo)
            video_url = (
                f"{BASE_URL}/image/{encoded_prompt}"
                f"?model={MODEL_VIDEO}"
                f"&seed={seed}"
                f"&width=1024&height=576" # Ø£Ø¨Ø¹Ø§Ø¯ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©
                f"&aspectRatio=16:9"
                f"&key={API_KEY}"
            )
            
            html_response = (
                f"ğŸ¥ <b>Genisi Cinema (Veo):</b> {user_input}<br>"
                f"<small style='color:#888'>{english_prompt}</small><br>"
                f"<video controls autoplay loop src='{video_url}' style='width:100%; border-radius:10px; margin-top:10px; box-shadow:0 5px 20px rgba(0,0,0,0.5);'></video>"
            )
            return jsonify({"reply": html_response})

        # ---------------------------------------------
        # ğŸ¨ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
        # ---------------------------------------------
        elif intent == "IMAGE":
            english_prompt = translate_prompt(user_input)
            encoded_prompt = urllib.parse.quote(english_prompt)
            seed = random.randint(0, 999999)
            
            image_url = (
                f"{BASE_URL}/image/{encoded_prompt}"
                f"?model={MODEL_IMAGE}&width=1024&height=1024&seed={seed}&nologo=true&key={API_KEY}"
            )
            html_response = (
                f"ğŸ¨ <b>Genisi Art:</b> {user_input}<br>"
                f"<small style='color:#888'>{english_prompt}</small><br>"
                f"<img src='{image_url}' alt='Generating...' style='width:100%; border-radius:10px; margin-top:10px;'>"
            )
            return jsonify({"reply": html_response})

        # ---------------------------------------------
        # ğŸ’¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ/Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©
        # ---------------------------------------------
        else:
            system_msg = "You are Genisi."
            if selected_model == MODEL_CHAT_CODE:
                system_msg = "You are Genisi Coder (Qwen). Expert developer."
            else:
                system_msg = "You are Genisi (OpenAI). Fast assistant."

            payload = {
                "model": selected_model,
                "messages": [
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": full_context}
                ],
                "temperature": 0.7
            }

            response = requests.post(
                f"{BASE_URL}/v1/chat/completions",
                headers=get_auth_headers(),
                json=payload, timeout=60
            )

            if response.status_code == 200:
                bot_reply = response.json()['choices'][0]['message']['content']
                badge = "âš¡ GPT-4o" if selected_model == MODEL_CHAT_FAST else "ğŸ’» Qwen-Coder"
                bot_reply = f"`[{badge}]`\n\n{bot_reply}"
                return jsonify({"reply": bot_reply})
            
            return jsonify({"reply": f"Error: {response.status_code}"}), 500

    except Exception as e:
        logger.error(f"Error: {e}")
        return jsonify({"reply": "Internal Server Error"}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=10000)
